# 线程&协程

使用python的threading模块进行多线程的操作



## 使用线程模块-threading

### 创建线程，启动线程

使用threading可以实现多线程调用

```python
# coding=utf-8

import threading
import time

def task(tId):
    print('当前线程编号：%s开始执行\n'%tId)
    time.sleep(1)

if __name__ == '__main__':
    for i in range(5):
        # 创建一个线程
        t = threading.Thread(target= task,args=(i,))
        # 执行这个线程
        t.start()
```

### 主线程等待子线程结束后结束

当所有的子线程都执行结束后，主线程才会结束

```python
# coding=utf-8

import threading
from time import sleep,ctime

def task1():
    for i in range(3):
        print('task1 execute %s'%i)
        sleep(1)

def task2():
    for i in range(3):
        print('task2 execute %s'%i)
        sleep(1)

if __name__ == '__main__':
    print('---start---%s'%ctime())
    t1 = threading.Thread(target=task1)
    t2 = threading.Thread(target=task2)

    t1.start()
    t2.start()

    print('---end---%s'%ctime())
    # 主线程会在所有的线程执行结束后结束，与java所不同
	# 通过enumerate 转换为数组判断个数
    while True:
        length = len(threading.enumerate())
        print('thread count:%s'%length)
        if length <=1 :
            break
        sleep(1)
```

### 继承Thread类实现run

```python
import threading
import time

class MyThread(threading.Thread):
    def run(self):
        for i in range(3):
            print('当前线程%s执行%s'%(self.name,i))
            time.sleep(1)

if __name__=='__main__':
    t = MyThread()
    t.start()

    t2 = MyThread()
    t2.start()
```

多线程程序的执行顺序是不确定的。当执行到sleep语句时，线程将被阻塞（Blocked），到sleep结束后，线程进入就绪（Runnable）状态，等待调度。而线程调度将自行选择一个线程执行。上面的代码中只能保证每个线程都运行完整个run函数，但是线程的启动顺序、run函数中每次循环的执行顺序都不能确定

每个线程一定会有一个名字，尽管上面的例子中没有指定线程对象的name，但是python会自动为线程指定一个名字。

当线程的run()方法结束时该线程完成。

无法控制线程调度程序，但可以通过别的方式来影响线程调度的方式。



### 共享全局变量

使用global进行调用全局变量，对于全局变量，2个线程共同使用

```python
from threading import Thread
import time

g_num = 10

def task1():
    global  g_num
    for i in range(3):
        g_num +=1
        print('task1 g_num %s'%g_num)

def task2():
    global g_num
    print('task2 g_num %s'%g_num)

if __name__== '__main__':
    print('start--%s'%g_num)
    t1 = Thread(target=task1)
    t2 = Thread(target=task2)

    t1.start()
    time.sleep(2)
    t2.start()
```

### 使用引用传递参数

多个线程可以使用同一个引用对象，但是会有线程安全问题

```python
# coding = utf-8
# 由于是共享的引用变量，不是线程安全的

from threading import Thread
import time

def task1(nums):
    nums.append(33)
    print('---task1---',nums)

def task2(nums):
    time.sleep(1)
    print('---task2---',nums)

if __name__ == '__main__':

    g_num = [1,2,3]
    t = Thread(target=task1,args=(g_num,))
    t2 = Thread(target=task2,args=(g_num,))
    t.start()
    t2.start()
# 结果：
---task1--- [1, 2, 3, 33]
---task2--- [1, 2, 3, 33]
```



## 与进程比较

### 定义

- 进程是系统进行资源分配和调度的一个独立单位.
- 线程是进程的一个实体,是CPU调度和分派的基本单位,它是比进程更小的能独立运行的基本单位.线程自己基本上不拥有系统资源,只拥有一点在运行中必不可少的资源(如程序计数器,一组寄存器和栈),但是它可与同属一个进程的其他的线程共享进程所拥有的全部资源.

### 区别

- 一个程序至少有一个进程,一个进程至少有一个线程.
- 线程的划分尺度小于进程(资源比进程少)，使得多线程程序的并发性高。
- 进程在执行过程中拥有独立的内存单元，而多个线程共享内存，从而极大地提高了程序的运行效率
- 线程不能够独立执行，必须依存在进程中
- 线程和进程在使用上各有优缺点：线程执行开销小，但不利于资源的管理和保护；而进程正相反



## 同步

共享数据同时操作，没有同步，造成数据与设定的不一样，如同时对一个数据进行+1000000次的操作，如果同步则最终的结果应该2000000

```python
# coding=utf-8
from threading import Thread
import time

g_num = 0;

def task1():
    global g_num
    for i in range(1000000):
        g_num += 1
    print('g_num--%s'%g_num)

def task2():
    global g_num
    for i in range(1000000):
        g_num += 1
    print('g_num--%s'%g_num)

if __name__ == '__main__':
    t = Thread(target=task1)
    t2 = Thread(target=task2)
    t.start()
    t2.start()
    print('g_num--%s'%g_num)
   
#结果
g_num--113748
g_num--1102430
g_num--1184782
```

### 互斥锁-threading的Lock

当多个线程几乎同时修改某一个共享数据的时候，需要进行同步控制

保证多个线程安全访问资源竞争的时候，需要引入同步机制，互斥锁

使用threading的Lock类，进行锁处理

```python
# 创建锁
mutex = threading.Lock()
# 锁定 blocking 默认阻塞 为True 表示当前线程获取锁的时候会阻塞 False 则当前线程不会阻塞
mutex.acquire([blocking])
# 释放
mutex.release()
```

示例

```python
# coding=utf-8
from threading import Thread,Lock
import time

g_num = 0

mutex = Lock()

def task1():
    global g_num
    for i in range(1000000):
        mutexFlag = mutex.acquire(True)
        if(mutexFlag):
            g_num += 1
            mutex.release()
    print('task1 g_num %s'%g_num)


def task2():
    global g_num
    for i in range(1000000):
        mutexFlag = mutex.acquire(True)
        if(mutexFlag):
            g_num += 1
            mutex.release()
    print('task2 g_num %s'%g_num)


if __name__ == '__main__':
    t = Thread(target=task1)
    t2 = Thread(target=task2)

    t.start()
    t2.start()

    print('main g_num %s'%g_num)
    
# 结果
main g_num 22371
task1 g_num 1957267
task2 g_num 2000000
```

锁的好处：

- 确保了某段关键代码只能由一个线程从头到尾完整地执行

锁的坏处：

- 阻止了多线程并发执行，包含锁的某段代码实际上只能以单线程模式执行，效率就大大地下降了
- 由于可以存在多个锁，不同的线程持有不同的锁，并试图获取对方持有的锁时，可能会造成死锁

### 死锁

在线程间共享多个资源的时候，如果两个线程分别占有一部分资源并且同时等待对方的资源，就会造成死锁。

存在多个锁的情况下容易产生死锁

```python
#coding=utf-8
import threading
import time

class MyThread1(threading.Thread):
    def run(self):
        if mutexA.acquire():
            print(self.name+'----do1---up----')
            time.sleep(1)

            if mutexB.acquire():
                print(self.name+'----do1---down----')
                mutexB.release()
            mutexA.release()

class MyThread2(threading.Thread):
    def run(self):
        if mutexB.acquire():
            print(self.name+'----do2---up----')
            time.sleep(1)
            if mutexA.acquire():
                print(self.name+'----do2---down----')
                mutexA.release()
            mutexB.release()

mutexA = threading.Lock()
mutexB = threading.Lock()

if __name__ == '__main__':
    t1 = MyThread1()
    t2 = MyThread2()
    t1.start()
    t2.start()
```

#### 避免死锁

- 程序设计时要尽量避免（银行家算法）
- 添加超时时间等

### 按顺序执行

使用互斥锁完成多个任务，有序的进程工作

```python
# coding=utf-8
from threading import Thread,Lock
import time

lock1 = Lock()
lock2 = Lock()
lock2.acquire()
lock3 = Lock()
lock3.acquire()

class Task1(Thread):
    def run(self):
        while True:
            if(lock1.acquire()):
                print('task1 -run')
                time.sleep(0.3)
                lock2.release()

class Task2(Thread):
    def run(self):
        while True:
            if(lock2.acquire()):
                print('task2 -run')
                time.sleep(0.3)
                lock3.release()

class Task3(Thread):
    def run(self):
        while True:
            if(lock3.acquire()):
                print('task3 -run')
                time.sleep(0.3)
                lock1.release()


if __name__ == '__main__':
    t1 = Task1()
    t2 = Task2()
    t3 = Task3()
    t1.start()
    t2.start()
    t3.start()
```



## 生产者消费者模式

Python的Queue模块中提供了同步的、线程安全的队列类，包括FIFO（先入先出)队列Queue，LIFO（后入先出）队列LifoQueue，和优先级队列PriorityQueue。这些队列都实现了锁原语（可以理解为原子操作，即要么不做，要么就做完），能够在多线程中直接使用。可以使用队列来实现线程间的同步

注意：不同于进程的queue，进程的是multiprocessing的Queue模块

线程安全的阻塞队列，使用queue的get和put以及qsize进行操作

```python
#coding = utf-8
import threading
import time

# python2中
# from Queue import Queue

#python3中
from queue import Queue

class Producer(threading.Thread):
    def run(self):
        global queue
        count = 0
        while(queue.qsize()<=100):
            for i in range(100):
                count +=1
                msg = self.name+'-p-'+str(count)
                queue.put(msg)
                print(msg)
            time.sleep(1)

class Consumer(threading.Thread):
    def run(self):
        global queue
        while(queue.qsize()>=100):
            for i in range(3):
                msg = self.name+'-c-'+queue.get()+'\n'
                print(msg)
            time.sleep(1)

if __name__ == '__main__':
    queue = Queue()
    for i in range(100):
        queue.put('start-'+str(i))

    # 创建多个生产者
    for i in range(2):
        p = Producer()
        p.start()

    # 创建多个消费者
    for i in range(4):
        c = Consumer()
        c.start()

    print('------')
```

- 为什么要使用生产者和消费者模式

在线程世界里，生产者就是生产数据的线程，消费者就是消费数据的线程。在多线程开发当中，如果生产者处理速度很快，而消费者处理速度很慢，那么生产者就必须等待消费者处理完，才能继续生产数据。同样的道理，如果消费者的处理能力大于生产者，那么消费者就必须等待生产者。为了解决这个问题于是引入了生产者和消费者模式。

- 什么是生产者消费者模式

生产者消费者模式是通过一个容器来解决生产者和消费者的强耦合问题。生产者和消费者彼此之间不直接通讯，而通过阻塞队列来进行通讯，所以生产者生产完数据之后不用等待消费者处理，直接扔给阻塞队列，消费者不找生产者要数据，而是直接从阻塞队列里取，阻塞队列就相当于一个缓冲区，平衡了生产者和消费者的处理能力。

这个阻塞队列就是用来给生产者和消费者解耦的。纵观大多数设计模式，都会找一个第三者出来进行解耦，



## ThreadLocal-threading.local()

在多线程环境下，每个线程都有自己的数据。一个线程使用自己的局部变量比使用全局变量好，因为局部变量只有线程自己能看见，不会影响其他线程，而全局变量的修改必须加锁

在使用局部变量的话，需要每个线程初始化的时候进行传递入参，如果入参过多则会很冗余

如果使用一个字典存储每个线程的局部变量，则可以避免传参的问题

ThreadLocal实现了该字典的功能

```python
import threading

threadLocal = threading.local()

def handleName():
    # 获取当前线程中的参数
    print(threading.current_thread().name+'--name--'+threadLocal.name)

def task(name):
    threadLocal.name = name
    handleName()

if __name__ == '__main__':
    t1 = threading.Thread(target=task,args=('zhangsan',),name='task1')
    t2 = threading.Thread(target=task,args=('zhangsan2',),name='task2')
    t1.start()
    t2.start()
    t1.join()
    t2.join()
```

把local_school看成全局变量，但每个属性如local_school.student都是线程的局部变量，可以任意读写而互不干扰，也不用管理锁的问题，ThreadLocal内部会处理

ThreadLocal最常用的地方就是为每个线程绑定一个数据库连接，HTTP请求，用户身份信息等，这样一个线程的所有调用到的处理函数都可以非常方便地访问这些资源

一个ThreadLocal变量虽然是全局变量，但每个线程都只能读写自己线程的独立副本，互不干扰。ThreadLocal解决了参数在一个线程中各个函数之间互相传递的问题



## 异步（进程实现）

- 同步调用就是你 喊 你朋友吃饭 ，你朋友在忙 ，你就一直在那等，等你朋友忙完了 ，你们一起去
- 异步调用就是你 喊 你朋友吃饭 ，你朋友说知道了 ，待会忙完去找你 ，你就去做别的了。
- 使用进程实现异步调用

```python
from multiprocessing import Pool
import time
import os

# 要在ubuntu下执行
# 执行函数，并返回一个值
def func1():
    print('pid %s ppid%s'%(os.getpid(),os.getppid()))
    for i in range(2):
        print('func1 run%s'%i)
        time.sleep(1)
    return 'param1'

def callBackFunc(args):
    print('callback pid%s'%os.getpid())
    print('params %s'%args)

if __name__=='__main__':
    pool = Pool(1)
    pool.apply_async(func=func1,callback=callBackFunc)
    time.sleep(10)
    print('main pid %s'%os.getpid())
    
# 结果
pid 6336 ppid6335
func1 run0
func1 run1
callback pid6335
params param1
main pid 6335
```



## GIL 全局解释器锁

先使用htop查看一下cpu情况

python的代码执行由python虚拟机（也叫解释器主循环，CPython版本）来控制，python在设计之初就考虑到在解释器的主循环中，同时只有一个线程在运行。即**在任意时刻只有一个线程在解释器中运行。对python虚拟机访问的控制由全局解释锁GIL控制，正是这个锁来控制同一时刻只有一个线程能够运行**

**在做IO操作时，GIL总是被释放。对所有面对内建的操作系统C代码的程序来说，GIL会在这个IO调用之前被释放，以允许其它的线程在等待这个IO的时候运行。如果是纯计算的程序，没有IO操作，解释器会每隔100次或每隔一定时间15ms去释放GIL。**

这里可以理解为IO密集型的python比计算密集型的程序更能利用多线程环境带来的便利

由于python使用了GIL，那么多线程是伪多线程，本质上是一个单线程，多个线程交替获取GIL进行执行，在CPython解释器中，而其他的解释器在python中对于多线程的解释不通，也就没有GIL一说

为了避免GIL带来的性能损耗，建议能使用多进程就不使用多线程进行处理，或者关键的部分使用c进行编写，然后用python进行调用解决，如

loop.c

```python
void DeadLoop()
{
    while(1)
    {
        ;
    }
}   
```

把一个ｃ语言文件编译成一个动态库的命令（linux平台下）:
gcc xxx.c -shared -o libxxxx.so

```python
from ctypes import *
from threading import Thread

#加载动态库
lib = cdll.LoadLibrary("./libdeadloop.so")

#创建一个子线程，让其执行ｃ语言编写的函数，此函数是一个死循环 关键部分调用
t = Thread(target=lib.DeadLoop)
t.start()

#主线程，也调用ｃ语言编写的那个死循环函数
#lib.DeadLoop()

while True:
    pass
```



# 协程

微线程，纤程，Coroutine

在python中使用生成器实现

比线程更小的执行单元。自带CPU上下文。

通俗的理解：在一个线程中的某个函数，可以在任何地方保存当前函数的一些临时变量等信息，然后切换到另外一个函数中执行，注意不是通过调用函数的方式做到的，并且切换的次数以及什么时候再切换到原来的函数都由开发者自己确定

## 与线程的差异

 线程切换从系统层面远不止保存和恢复 CPU上下文这么简单。 操作系统为了程序运行的高效性每个线程都有自己缓存Cache等等数据，操作系统还会帮你做这些数据的恢复操作。 所以线程的切换非常耗性能。但是协程的切换只是单纯的操作CPU的上下文，所以一秒钟切换个上百万次系统都抗的住

但是协程有一个问题，就是系统并不感知，所以操作系统不会帮你做切换。 那么谁来帮你做切换？让需要执行的协程更多的获得CPU时间才是问题的关键

## 协程框架原理

目前的协程框架一般都是设计成 1:N 模式。所谓 1:N 就是一个线程作为一个容器里面放置多个协程。 那么谁来适时的切换这些协程？答案是有协程自己主动让出CPU，也就是每个协程池里面有一个调度器， 这个调度器是被动调度的。意思就是他不会主动调度。而且当一个协程发现自己执行不下去了(比如异步等待网络的数据回来，但是当前还没有数据到)， 这个时候就可以由这个协程通知调度器，这个时候执行到调度器的代码，调度器根据事先设计好的调度算法找到当前最需要CPU的协程。 切换这个协程的CPU上下文把CPU的运行权交个这个协程，直到这个协程出现执行不下去需要等等的情况，或者它调用主动让出CPU的API之类，触发下一次调度

### 问题

假设这个线程中有一个协程是CPU密集型的他没有IO操作， 也就是自己不会主动触发调度器调度的过程，那么就会出现其他协程得不到执行的情况， 所以这种情况下需要程序员自己避免。这是一个问题，假设业务开发的人员并不懂这个原理的话就可能会出现问题

## 好处

在IO密集型的程序中由于IO操作远远慢于CPU的操作，所以往往需要CPU去等IO操作。 同步IO下系统需要切换线程，让操作系统可以在IO过程中执行其他的东西。 这样虽然代码是符合人类的思维习惯但是由于大量的线程切换带来了大量的性能的浪费，尤其是IO密集型的程序。

所以人们发明了异步IO。就是当数据到达的时候触发我的回调。来减少线程切换带来性能损失。 但是这样的坏处也是很大的，主要的坏处就是操作被 “分片” 了，代码写的不是 “一气呵成” 这种。 而是每次来段数据就要判断 数据够不够处理哇，够处理就处理吧，不够处理就在等等吧。这样代码的可读性很低，其实也不符合人类的习惯。

但是协程可以很好解决这个问题。比如 把一个IO操作 写成一个协程。当触发IO操作的时候就自动让出CPU给其他协程。要知道协程的切换很轻的。 协程通过这种对异步IO的封装 既保留了性能也保证了代码的容易编写和可读性。在高IO密集型的程序下很好。但是高CPU密集型的程序下没啥好处

自己控制协程的分配运行，不存在竞争抢占cpu资源

## 简单实现

```python
import time

def A():
    while True:
        print("----A---")
        yield
        time.sleep(0.5)

def B(c):
    while True:
        print("----B---")
        # c.next() python2 支持
        c.__next__() # python3 支持
        time.sleep(0.5)

if __name__=='__main__':
    a = A()
    B(a)
    
# 结果 a 和 b交替运行
--B--
--A--
--B--
--A--
--B--
--A--
```



## greenlet实现协程

需要安装，greenlet是用c写的

```python
sudo pip install greenlet
```

具体使用：在pycharm注意运行模式，如果是unittests模式则不显示结果，需要修改edit configuration

```python
# coding=utf-8
from greenlet import greenlet
import time

def test1():
    while True:
        print('---test1---')
        gl2.switch()
        time.sleep(1)

def test2():
    while True:
        print('---test2---')
        gl1.switch()
        time.sleep(0.5)

gl1 = greenlet(test1)
gl2 = greenlet(test2)

if __name__== '__main__':
    # 先切换到第一个协程处理
    gl1.switch()
 
#结果
---test1---
---test2---
---test1---
---test2---
```



## gevent实现协程

greenlet已经实现了协程，但是这个还的人工切换，是不是觉得太麻烦了，不要捉急，python还有一个比greenlet更强大的并且能够自动切换任务的模块`gevent`

其原理是当一个greenlet遇到IO(指的是input output 输入输出，比如网络、文件操作等)操作时，比如访问网络，就自动切换到其他的greenlet，等到IO操作完成，再在适当的时候切换回来继续执行。

由于IO操作非常耗时，经常使程序处于等待状态，有了gevent为我们自动切换协程，就保证总有greenlet在运行，而不是等待IO

需要安装

```python
sudo pip install gevent
```

### 简单使用

